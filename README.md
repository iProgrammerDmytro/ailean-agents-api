# AileanÂ AgentsÂ APIÂ Backend

> **FastAPIÂ +Â PostgreSQL microservice** â€“ codingâ€‘challenge backend

---

## âœ¨ Features

- CRUD endpoints for **Agents**
- Q&A endpoint for the **Hotel Q&A Bot**
- OpenAPI schema served at `/docs`
- 100â€¯% typed codebase
- Alembic migrations & PostgreSQL
- Full testâ€‘suite with **pytest**
- **Dockerâ€‘first** developer experience

---

## ğŸ–¥ï¸ QuickÂ Start (DockerÂ Compose)

### 1.Â Clone the Repository

```bash
git clone https://github.com/iProgrammerDmytro/ailean-agents-api.git
cd aileanâ€‘agentsâ€‘api
```

### 2.Â BuildÂ &Â Run the Stack

```bash
docker compose up --build   # first time (build + run)
# docker compose up         # subsequent runs
```

The API will be available at **http://localhost:8000**  
Interactive Swagger UI: **http://localhost:8000/docs**

---

## ğŸ—ºï¸ API Reference

| Method | Path | Description |
| :----: | :--- | :---------- |
| GET    | `/agents` | List agents |
| POST   | `/agents` | Create agent |
| GET    | `/agents/{agent_id}` | Retrieve single agent |
| POST   | `/agents/{agent_id}/ask` | Ask Hotel Q&A bot |

---

## âš™ï¸ Common Tasks

| Task | Command |
| ---- | ------- |
| Run migrations | `docker compose exec api alembic upgrade head` |
| Start interactive shell | `docker compose exec api bash` |
| **Run the testâ€‘suite** | `pytest -q` |

> **Note:** To execute tests, first install the test requirements and then run `pytest`:
>
> ```bash
> pip install -r requirements.test.txt
> pytest
> ```

---

## ğŸ“‚ ProjectÂ Layout

```
app/
â”œâ”€ agent/          # business domain logic
â”‚  â”œâ”€ models.py    # SQLAlchemy models
â”‚  â”œâ”€ schemas.py   # Pydantic DTOs
â”‚  â”œâ”€ crud.py      # persistence helpers
â”‚  â”œâ”€ routes.py    # API router
â”‚  â””â”€ services/    # domain services (Hotel Q&A, etc.)
â”œâ”€ db/             # database helpers & Alembic glue
â”œâ”€ core/           # settings & shared utilities
â””â”€ main.py         # FastAPI application factory
```

---

## ğŸ“¦ Sample Payload â€“ `POST /agents`

| Field | Type | Allowed values | Notes |
|-------|------|---------------|-------|
| `name` | `string` | â€” | Humanâ€‘readable name |
| `type` | enum | `Sales`Â â€¢Â `Support`Â â€¢Â `Marketing` | Agent category |
| `status` | enum | `Active`Â â€¢Â `Inactive` | Operational state |
| `description` | `string` | â€” | Optional longer text |

### Minimal payload (as shown in `/docs`)

```jsonc
{
  "name": "string",
  "type": "Sales",
  "status": "Active",
  "description": "string",
}
```

### Realistic example â€“ Hotel Q&A Bot

```jsonc
{
  "name": "Hotel Q&A Bot",
  "type": "Support",
  "status": "Active",
  "description": "Answers common questions about TheÂ GrandÂ Arosa popâ€‘up hotel.",
}
```

---

## ğŸ§  Q&A Matching Logic â€“ Under the Hood

The hotel botâ€™s intelligence is deliberately lightweight: it trades complex NLP for **deterministic, lowâ€‘latency string matching** that is **100â€¯% edgeâ€‘deployable** (zero external dependencies).

### 1.Â Knowledge Base

A constant dictionary `_QA_PAIRS: dict[str, str]` contains curated Qâ†’A pairs extracted from the hotel website. Each **key** is a concise keyword/phrase (â‰ˆÂ 10 entries) and the **value** is the full answer text.

### 2.Â NormalisationÂ `_norm()`

```python
def _norm(s: str) -> str:
    return "".join(ch for ch in s.lower() if ch.isalnum())
```

* Lowerâ€‘cases the string and strips all nonâ€‘alphanumeric characters.  
* Ensures `"Check-in!"`, `"checkin"`, and `"CHECKâ€‘IN"` collapse to the same token â†’ `checkin`.  
* Guarantees canonical forms for both user input and KB keys.

### 3.Â Exact / Subâ€‘string Pass

```python
for k, v in _QA_PAIRS.items():
    if k_norm in q_norm or q_norm in k_norm:
        return v
```

* **O(N)** over at most 10 entries â€“ trivial cost.  
* Handles perfect matches and queries that wholly contain the keyword (e.g. â€œWhat time is checkâ€‘in?â€ âŸ¶ `checkin`).

### 4.Â Fuzzy Pass with `SequenceMatcher`

```python
best_key = max(_QA_PAIRS, key=lambda k: _ratio(q_norm, _norm(k)))
if _ratio(q_norm, _norm(best_key)) >= 0.56:
    return _QA_PAIRS[best_key]
```

* Uses `difflib.SequenceMatcher` (stdâ€‘lib) for a **cheap Levenshteinâ€‘style similarity** score.  
* ThresholdÂ `0.56` was empirically chosen to catch typos like â€œcheeckinâ€ without producing false positives.  
* Still **deterministic and offline** â€“ no ML models or cloud calls.

### 5.Â Fallback

If neither pass succeeds:  
`"Sorry, I couldn't find an answer to that."` â€“ keeps UX explicit and graceful.

### 6.Â Complexity & Performance

* Runtime: O(N) where NÂ =Â number of KB entries (â‰¤Â 10 â‡’ ~microseconds).  
* Memory: O(N) for the dict + negligible stack.  
* No I/O, so **p99 latency stays in subâ€‘millisecond territory** on tiny containers (â‰ˆÂ 10â€¯MiB RSS).

### 7.Â Why This Design?

| Goal | Design choice | Payâ€‘off |
|------|---------------|---------|
| **Maximum ROI** | Plain Python, stdâ€‘lib only | Ships in minutes; no extra infra |
| Edge / offline | Deterministic dict + fuzzy ratio | Works in Lambda@Edge / Cloudflare |
| Maintainability | `_QA_PAIRS` is declarative | Marketing can edit answers without code changes |
| Testability | Pure functions (`answer()`) | Unitâ€‘tests run in <Â 1â€¯ms |
| Predictability | No LLM randomness | Same input â‡’ same output (good for legal/compliance) |

### 8.Â Extensibility

* **Synonyms** â€“ append more keys (e.g. `"parking fee"`).  
* **Dynamic KB** â€“ swap the dict for a SQLite table or Redis hash.  

---

Future iterations could integrate an LLM fallback while preserving this deterministic firstâ€‘line lookup (â€œhybrid retrievalâ€). For the current scope, the above logic nails the **â€œ80â€¯% questions solved with 20â€¯% effortâ€** ethos.

---

# ğŸ“‰ Limitations, Tradeâ€‘offsÂ &â€¯FutureÂ Improvements

> A technical audit of the current MVP, with a pragmatic roadmap for levellingâ€‘up to productionâ€‘grade.

---

## 1â€¯Â Current Limitations

### 1.1Â QA System Architecture

| Issue | Impact |
|-------|--------|
| **Hardâ€‘coded KB**Â â€“ Q&A pairs live in a Python dict | Content updates require code deploy |
| **Primitive matching** | Simple fuzzy matching with `difflib.SequenceMatcher` |
| **No semantic understanding** | Cannot handle synonyms, context, or natural language variations |
| **Static content** | Requires code deployment to update hotel information |
| **Single domain** | Logic tied to *TheÂ GrandÂ Arosa* â€“ no multiâ€‘hotel support |

### 1.2Â Production Readiness Gaps

| Gap | Consequence |
|-----|-------------|
| Devâ€‘only Docker Compose with **hardâ€‘coded creds** | Secrets leak risk |
| No Production Configuration | Missing optimized container images |
| **CORS `*`**, no auth, no rate limiting | Wide attack surface |
| Missing logging / metrics | No observability, harder incident response |

### 1.3Â Scalability Constraints

* No cache â€“ every call executes full matching logic (OK now, risky at scale)  
* Single DB pool â€“ connection exhaustion under load

### 1.4Â Testing & Delivery

* Unit coverage below 60â€¯%  
* Manual deployment â€“ **zero CI/CD**

---

## 2â€¯Â Recommended ImprovementsÂ (prioritised)

### 2.1Â Harden Production RuntimeÂ ğŸ”¥

1. Inject secrets via `dockerâ€‘compose.yml` â†’ `.env`, no plaintext creds  
2. Add `fastapiâ€‘limiter`, `fastapiâ€‘users`, and strict CORS origins  

### 2.2Â Comprehensive Test Strategy

| Layer | Goal |
|-------|------|
| **Unit** | 90â€¯%+ coverage of pure functions & services |
| **Integration** | DB migrations, external APIs |
| **E2E / Contract** | Validate JSON schemas & happyâ€‘paths |

Add GitHubÂ Actions workflow: lintÂ â†’ testÂ â†’ buildÂ â†’ push image.

### 2.3Â Architecture Evolution â€“ From DictÂ â†’Â RAG

```
app/core/services/knowledge/
â”œâ”€ scraper.py          # collect hotel website data
â”œâ”€ embeddings.py       # sentenceâ€‘transformers
â”œâ”€ retrieval.py        # vector search (pgvector / ChromaDB)
â””â”€ pipeline.py         # orchestration
```

**Key deps**  
`sentenceâ€‘transformers 2.7.*` â€¢ `chromadb 0.4.*` (or `pgvector`) â€¢ `celery 5.3.*` â€¢ `redis 5`

```python
class KnowledgeService:
    async def query(self, question: str) -> str:
        if (ans := await self._exact_match(question)):
            return ans              # âš¡ fastâ€‘path

        rag_res = await self._rag_query(question)
        if rag_res.confidence >= 0.7:
            return rag_res.text     # ğŸ¤– semantic path

        return self.fallback_msg    # ğŸ™ˆ fallback
```

**Background Tasks**
```python
@celery.task
def scrape_hotel_data():
    content = scrape_grandarosa_website()
    embeds  = generate_embeddings(content)
    store_in_vector_db(embeds)
```

### 2.4Â Operational Excellence

* Structured JSON logging 
* Prometheus metrics + Grafana dashboards  
* Alerting when confidence scores dip

---

## 3â€¯Â Tradeâ€‘offsÂ Analysis

| Aspect | CurrentÂ (dict lookup) | FutureÂ (RAG pipeline) |
|--------|----------------------|-----------------------|
| **Setup complexity** | â­â­ Simple | â­â­â­â­â­ Complex |
| **Latency** | â­â­â­â­â­Â &lt;10â€¯ms | â­â­â­Â 100â€‘500â€¯ms |
| **Accuracy** | â­â­ Basic | â­â­â­â­â­ High |
| **Scalability** | â­â­ Limited | â­â­â­â­â­ Excellent |
| **Maintenance** | â­ Manual | â­â­â­â­ Automated |
| **Cost** | â­â­â­â­â­ Minimal | â­â­â­ Moderate |

---

## 4â€¯Â Additional Recommendations

* **VectorÂ DB**: Prefer `pgvector` inside Postgres â€“ single infra, easy backups  
* **LLM**: Start with OpenAI API; evaluate openâ€‘source (`Mistralâ€‘7B`, `Llamaâ€‘3â€‘8B`) later  
* **Cache & Queue**: Redis for both caching layer and Celery broker  
* **Business KPIs**: Track query resolution rates and user satisfaction; A/B test dict vs RAG responses

---
